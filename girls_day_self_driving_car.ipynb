{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "model_how_to_sim_self_driving_car.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XqTp9KRv-FT3",
        "outputId": "c72bbec6-3bfe-4c52-f72d-600570df51ab"
      },
      "source": [
        "# Mount my Google Drive.  It will ask for an authenticate code\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JrSbb_NnwIo7"
      },
      "source": [
        "import cv2, os\n",
        "import numpy as np\n",
        "import matplotlib.image as mpimg\n",
        "\n",
        "IMAGE_HEIGHT, IMAGE_WIDTH, IMAGE_CHANNELS = 66, 200, 3\n",
        "INPUT_SHAPE = (IMAGE_HEIGHT, IMAGE_WIDTH, IMAGE_CHANNELS)\n",
        "\n",
        "\n",
        "def load_image(data_dir, image_file):\n",
        "    \"\"\"\n",
        "    Load RGB images from a file\n",
        "    \"\"\"\n",
        "    return mpimg.imread(os.path.join(data_dir, image_file.strip()))\n",
        "\n",
        "\n",
        "def crop(image):\n",
        "    \"\"\"\n",
        "    Crop the image (removing the sky at the top and the car front at the bottom)\n",
        "    \"\"\"\n",
        "    return image[60:-25, :, :] # remove the sky and the car front\n",
        "\n",
        "\n",
        "def resize(image):\n",
        "    \"\"\"\n",
        "    Resize the image to the input shape used by the network model\n",
        "    \"\"\"\n",
        "    return cv2.resize(image, (IMAGE_WIDTH, IMAGE_HEIGHT), cv2.INTER_AREA)\n",
        "\n",
        "\n",
        "def rgb2yuv(image):\n",
        "    \"\"\"\n",
        "    Convert the image from RGB to YUV (This is what the NVIDIA model does)\n",
        "    \"\"\"\n",
        "    return cv2.cvtColor(image, cv2.COLOR_RGB2YUV)\n",
        "\n",
        "\n",
        "def preprocess(image):\n",
        "    \"\"\"\n",
        "    Combine all preprocess functions into one\n",
        "    \"\"\"\n",
        "    image = crop(image)\n",
        "    image = resize(image)\n",
        "    image = rgb2yuv(image)\n",
        "    return image\n",
        "\n",
        "\n",
        "def choose_image(data_dir, center, left, right, steering_angle):\n",
        "    \"\"\"\n",
        "    Randomly choose an image from the center, left or right, and adjust\n",
        "    the steering angle.\n",
        "    \"\"\"\n",
        "    choice = np.random.choice(3)\n",
        "    if choice == 0:\n",
        "        return load_image(data_dir, left), steering_angle + 0.2\n",
        "    elif choice == 1:\n",
        "        return load_image(data_dir, right), steering_angle - 0.2\n",
        "    return load_image(data_dir, center), steering_angle\n",
        "\n",
        "\n",
        "def random_flip(image, steering_angle):\n",
        "    \"\"\"\n",
        "    Randomly flipt the image left <-> right, and adjust the steering angle.\n",
        "    \"\"\"\n",
        "    if np.random.rand() < 0.5:\n",
        "        image = cv2.flip(image, 1)\n",
        "        steering_angle = -steering_angle\n",
        "    return image, steering_angle\n",
        "\n",
        "\n",
        "def random_translate(image, steering_angle, range_x, range_y):\n",
        "    \"\"\"\n",
        "    Randomly shift the image virtially and horizontally (translation).\n",
        "    \"\"\"\n",
        "    trans_x = range_x * (np.random.rand() - 0.5)\n",
        "    trans_y = range_y * (np.random.rand() - 0.5)\n",
        "    steering_angle += trans_x * 0.002\n",
        "    trans_m = np.float32([[1, 0, trans_x], [0, 1, trans_y]])\n",
        "    height, width = image.shape[:2]\n",
        "    image = cv2.warpAffine(image, trans_m, (width, height))\n",
        "    return image, steering_angle\n",
        "\n",
        "\n",
        "def random_shadow(image):\n",
        "    \"\"\"\n",
        "    Generates and adds random shadow\n",
        "    \"\"\"\n",
        "    # (x1, y1) and (x2, y2) forms a line\n",
        "    # xm, ym gives all the locations of the image\n",
        "    x1, y1 = IMAGE_WIDTH * np.random.rand(), 0\n",
        "    x2, y2 = IMAGE_WIDTH * np.random.rand(), IMAGE_HEIGHT\n",
        "    xm, ym = np.mgrid[0:IMAGE_HEIGHT, 0:IMAGE_WIDTH]\n",
        "\n",
        "    # mathematically speaking, we want to set 1 below the line and zero otherwise\n",
        "    # Our coordinate is up side down.  So, the above the line: \n",
        "    # (ym-y1)/(xm-x1) > (y2-y1)/(x2-x1)\n",
        "    # as x2 == x1 causes zero-division problem, we'll write it in the below form:\n",
        "    # (ym-y1)*(x2-x1) - (y2-y1)*(xm-x1) > 0\n",
        "    mask = np.zeros_like(image[:, :, 1])\n",
        "    mask[np.where((ym - y1) * (x2 - x1) - (y2 - y1) * (xm - x1) > 0)] = 1\n",
        "\n",
        "    # choose which side should have shadow and adjust saturation\n",
        "    cond = mask == np.random.randint(2)\n",
        "    s_ratio = np.random.uniform(low=0.2, high=0.5)\n",
        "\n",
        "    # adjust Saturation in HLS(Hue, Light, Saturation)\n",
        "    hls = cv2.cvtColor(image, cv2.COLOR_RGB2HLS)\n",
        "    hls[:, :, 1][cond] = hls[:, :, 1][cond] * s_ratio\n",
        "    return cv2.cvtColor(hls, cv2.COLOR_HLS2RGB)\n",
        "\n",
        "\n",
        "def random_brightness(image):\n",
        "    \"\"\"\n",
        "    Randomly adjust brightness of the image.\n",
        "    \"\"\"\n",
        "    # HSV (Hue, Saturation, Value) is also called HSB ('B' for Brightness).\n",
        "    hsv = cv2.cvtColor(image, cv2.COLOR_RGB2HSV)\n",
        "    ratio = 1.0 + 0.4 * (np.random.rand() - 0.5)\n",
        "    hsv[:,:,2] =  hsv[:,:,2] * ratio\n",
        "    return cv2.cvtColor(hsv, cv2.COLOR_HSV2RGB)\n",
        "\n",
        "\n",
        "def augment(data_dir, center, left, right, steering_angle, range_x=100, range_y=10):\n",
        "    \"\"\"\n",
        "    Generate an augmented image and adjust steering angle.\n",
        "    (The steering angle is associated with the center image)\n",
        "    \"\"\"\n",
        "    image, steering_angle = choose_image(data_dir, center, left, right, steering_angle)\n",
        "    image, steering_angle = random_flip(image, steering_angle)\n",
        "    image, steering_angle = random_translate(image, steering_angle, range_x, range_y)\n",
        "    image = random_shadow(image)\n",
        "    image = random_brightness(image)\n",
        "    return image, steering_angle\n",
        "\n",
        "\n",
        "def batch_generator(data_dir, image_paths, steering_angles, batch_size, is_training):\n",
        "    \"\"\"\n",
        "    Generate training image give image paths and associated steering angles\n",
        "    \"\"\"\n",
        "    images = np.empty([batch_size, IMAGE_HEIGHT, IMAGE_WIDTH, IMAGE_CHANNELS])\n",
        "    steers = np.empty(batch_size)\n",
        "    while True:\n",
        "        i = 0\n",
        "        for index in np.random.permutation(image_paths.shape[0]):\n",
        "            center, left, right = image_paths[index]\n",
        "            steering_angle = steering_angles[index]\n",
        "            # argumentation\n",
        "            if is_training and np.random.rand() < 0.6:\n",
        "                image, steering_angle = augment(data_dir, center, left, right, steering_angle)\n",
        "            else:\n",
        "                image = load_image(data_dir, center) \n",
        "            # add the image and steering angle to the batch\n",
        "            images[i] = preprocess(image)\n",
        "            steers[i] = steering_angle\n",
        "            i += 1\n",
        "            if i == batch_size:\n",
        "                break\n",
        "        yield images, steers"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U_tAQsB5W-ZZ"
      },
      "source": [
        "import pandas as pd # data analysis toolkit - create, read, update, delete datasets\n",
        "import numpy as np #matrix math\n",
        "from sklearn.model_selection import train_test_split #to split out training and testing data\n",
        "#keras is a high level wrapper on top of tensorflow (machine learning library)\n",
        "#The Sequential container is a linear stack of layers\n",
        "from keras.models import Sequential\n",
        "#popular optimization strategy that uses gradient descent\n",
        "from keras.optimizers import Adam\n",
        "#to save our model periodically as checkpoints for loading later\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "#what types of layers do we want our model to have?\n",
        "from keras.layers import Lambda, Conv2D, MaxPooling2D, Dropout, Dense, Flatten\n",
        "#for command line arguments\n",
        "import argparse\n",
        "#for reading files\n",
        "import os\n",
        "\n",
        "#for debugging, allows for reproducible (deterministic) results\n",
        "np.random.seed(0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_sSjg8SJXAZ4"
      },
      "source": [
        "def load_data(args):\n",
        "    \"\"\"\n",
        "    Load training data and split it into training and validation set\n",
        "    \"\"\"\n",
        "    #reads CSV file into a single dataframe variable\n",
        "    data_df = pd.read_csv(os.path.join(os.getcwd(), args['data_dir'], 'driving_log.csv'), names=['center', 'left', 'right', 'steering', 'throttle', 'reverse', 'speed'])\n",
        "\n",
        "    #yay dataframes, we can select rows and columns by their names\n",
        "    #we'll store the camera images as our input data\n",
        "    X = data_df[['center', 'left', 'right']].values\n",
        "    #and our steering commands as our output data\n",
        "    y = data_df['steering'].values\n",
        "\n",
        "    #now we can split the data into a training (80), testing(20), and validation set\n",
        "    #thanks scikit learn\n",
        "    X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=args['test_size'], random_state=0)\n",
        "\n",
        "    return X_train, X_valid, y_train, y_valid"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dVWK_graXL6l"
      },
      "source": [
        "def build_model(args):\n",
        "    \"\"\"\n",
        "    NVIDIA model used\n",
        "    Image normalization to avoid saturation and make gradients work better.\n",
        "    Convolution: 5x5, filter: 24, strides: 2x2, activation: ELU\n",
        "    Convolution: 5x5, filter: 36, strides: 2x2, activation: ELU\n",
        "    Convolution: 5x5, filter: 48, strides: 2x2, activation: ELU\n",
        "    Convolution: 3x3, filter: 64, strides: 1x1, activation: ELU\n",
        "    Convolution: 3x3, filter: 64, strides: 1x1, activation: ELU\n",
        "    Drop out (0.5)\n",
        "    Fully connected: neurons: 100, activation: ELU\n",
        "    Fully connected: neurons: 50, activation: ELU\n",
        "    Fully connected: neurons: 10, activation: ELU\n",
        "    Fully connected: neurons: 1 (output)\n",
        "\n",
        "    # the convolution layers are meant to handle feature engineering\n",
        "    the fully connected layer for predicting the steering angle.\n",
        "    dropout avoids overfitting\n",
        "    ELU(Exponential linear unit) function takes care of the Vanishing gradient problem.\n",
        "    \"\"\"\n",
        "    model = Sequential()\n",
        "    model.add(Lambda(lambda x: x/127.5-1.0, input_shape=INPUT_SHAPE))\n",
        "    model.add(Conv2D(24, 5, activation='elu', strides=(2, 2)))\n",
        "    model.add(Conv2D(36, 5, activation='elu', strides=(2, 2)))\n",
        "    model.add(Conv2D(48, 5, activation='elu', strides=(2, 2)))\n",
        "    model.add(Conv2D(64, 3, activation='elu'))\n",
        "    model.add(Conv2D(64, 3, activation='elu'))\n",
        "    model.add(Dropout(args['keep_prob']))\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(100, activation='elu'))\n",
        "    model.add(Dense(50, activation='elu'))\n",
        "    model.add(Dense(10, activation='elu'))\n",
        "    model.add(Dense(1))\n",
        "    model.summary()\n",
        "\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZMy6wWFuXOzZ"
      },
      "source": [
        "def train_model(model, args, X_train, X_valid, y_train, y_valid):\n",
        "    \"\"\"\n",
        "    Train the model\n",
        "    \"\"\"\n",
        "    #Saves the model after every epoch.\n",
        "    #quantity to monitor, verbosity i.e logging mode (0 or 1),\n",
        "    #if save_best_only is true the latest best model according to the quantity monitored will not be overwritten.\n",
        "    #mode: one of {auto, min, max}. If save_best_only=True, the decision to overwrite the current save file is\n",
        "    # made based on either the maximization or the minimization of the monitored quantity. For val_acc,\n",
        "    #this should be max, for val_loss this should be min, etc. In auto mode, the direction is automatically\n",
        "    # inferred from the name of the monitored quantity.\n",
        "    checkpoint = ModelCheckpoint('model-{epoch:03d}.h5',\n",
        "                                 monitor='val_loss',\n",
        "                                 verbose=0,\n",
        "                                 save_best_only=args['save_best_only'],\n",
        "                                 mode='auto')\n",
        "\n",
        "    #calculate the difference between expected steering angle and actual steering angle\n",
        "    #square the difference\n",
        "    #add up all those differences for as many data points as we have\n",
        "    #divide by the number of them\n",
        "    #that value is our mean squared error! this is what we want to minimize via\n",
        "    #gradient descent\n",
        "    model.compile(loss='mean_squared_error', optimizer=Adam(lr=args['learning_rate']))\n",
        "\n",
        "    #Fits the model on data generated batch-by-batch by a Python generator.\n",
        "\n",
        "    #The generator is run in parallel to the model, for efficiency.\n",
        "    #For instance, this allows you to do real-time data augmentation on images on CPU in\n",
        "    #parallel to training your model on GPU.\n",
        "    #so we reshape our data into their appropriate batches and train our model simulatenously\n",
        "    model.fit_generator(batch_generator(args['data_dir'], X_train, y_train, args['batch_size'], True),\n",
        "                        args['samples_per_epoch'],\n",
        "                        args['nb_epoch'],\n",
        "                        max_queue_size=1,\n",
        "                        validation_data=batch_generator(args['data_dir'], X_valid, y_valid, args['batch_size'], False),\n",
        "                        validation_steps=len(X_valid), # // args['batch_size'],\n",
        "                        callbacks=[checkpoint],\n",
        "                        verbose=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-8rkVD_0XR94"
      },
      "source": [
        "#for command line args\n",
        "def s2b(s):\n",
        "    \"\"\"\n",
        "    Converts a string to boolean value\n",
        "    \"\"\"\n",
        "    s = s.lower()\n",
        "    return s == 'true' or s == 'yes' or s == 'y' or s == '1'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-gqqTAuQXb4B",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 990
        },
        "outputId": "7e65df36-f2bd-4e35-9ddd-fde604e121a6"
      },
      "source": [
        "args = {\n",
        "    \"data_dir\":\"/content/gdrive/MyDrive/train_img\",\n",
        "    \"test_size\": 0.2,\n",
        "    \"keep_prob\": 0.5,\n",
        "    \"nb_epoch\": 10,\n",
        "    \"samples_per_epoch\": 1000,\n",
        "    \"batch_size\": 40,\n",
        "    \"save_best_only\": True,\n",
        "    \"learning_rate\": 1.0e-4\n",
        "}\n",
        "#load data\n",
        "data = load_data(args)\n",
        "#build model\n",
        "model = build_model(args)\n",
        "#train model on data, it saves as model.h5\n",
        "train_model(model, args, *data)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "lambda (Lambda)              (None, 66, 200, 3)        0         \n",
            "_________________________________________________________________\n",
            "conv2d (Conv2D)              (None, 31, 98, 24)        1824      \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 14, 47, 36)        21636     \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 5, 22, 48)         43248     \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 3, 20, 64)         27712     \n",
            "_________________________________________________________________\n",
            "conv2d_4 (Conv2D)            (None, 1, 18, 64)         36928     \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 1, 18, 64)         0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 1152)              0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 100)               115300    \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 50)                5050      \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 10)                510       \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 1)                 11        \n",
            "=================================================================\n",
            "Total params: 252,219\n",
            "Trainable params: 252,219\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            " 441/1000 [============>.................] - ETA: 1:15:48 - loss: 0.0483"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-d50d7fd79280>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuild_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;31m#train model on data, it saves as model.h5\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-7-9730e40bd2ab>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model, args, X_train, X_valid, y_train, y_valid)\u001b[0m\n\u001b[1;32m     37\u001b[0m                         \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_valid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;31m# // args['batch_size'],\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m                         \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcheckpoint\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m                         verbose=1)\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1859\u001b[0m         \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1860\u001b[0m         \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1861\u001b[0;31m         initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1862\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1863\u001b[0m   def evaluate_generator(self,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1098\u001b[0m                 _r=1):\n\u001b[1;32m   1099\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1100\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1101\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xla\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    853\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    854\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 855\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    856\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    857\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2941\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   2942\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 2943\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   2944\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2945\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1917\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1918\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1919\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1920\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1921\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    558\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 560\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    561\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ]
}